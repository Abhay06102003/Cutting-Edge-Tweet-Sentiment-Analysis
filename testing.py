# -*- coding: utf-8 -*-
"""Testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oEDlNqscaKtc2BuDWmjYW2PpXrM2aUbC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

test = pd.read_csv('test.csv')
test

from sklearn.preprocessing import LabelEncoder as le
le1 = le()
test['sentiment'] = le1.fit_transform(test['sentiment'])
test

tweets = test.values[:,1]
labels = test.values[:,2]

from sklearn.preprocessing import OneHotEncoder as oe
oe1 = oe()
labels1 = oe1.fit_transform(np.array(labels).reshape(3534,1)).todense()
labels1.shape

!pip install sentence-transformers
from sentence_transformers import SentenceTransformer
bert_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

embeddings = bert_model.encode(tweets, show_progress_bar=True)
print(embeddings.shape)

from tensorflow.keras.models import load_model
model = load_model('model.h5')

y_pred = model.predict(embeddings)
y_pred

y_pred = np.argmax(y_pred,axis = 1)
y_pred

count = 0
for i in range(3534):
  if(y_pred[i] == labels[i]):
    count+=1
print('accuracy = ',(count/3534)*100)

