# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IqNlEEwwKbf4Os1bNUre62LwKoKYGh7B
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow_hub as hub
import tensorflow_text as text

df = pd.read_csv('train.csv')
df.drop(columns = 'selected_text',inplace = True)
df

from sklearn.preprocessing import LabelEncoder as le
le1 = le()
df['sentiment'] = le1.fit_transform(df['sentiment'])
df

tweets = df.values[:,1]
labels = df.values[:,2]
print (tweets[40], labels[40])
print (tweets[8002], labels[8002])

from sklearn.preprocessing import OneHotEncoder as oe
oe1 = oe()
labels1 = oe1.fit_transform(np.array(labels).reshape(27481,1)).todense()
labels1.shape

from sklearn.utils.class_weight import compute_class_weight as cc
class_weights = cc(class_weight = 'balanced',classes = [0,1,2],y = list(labels))
class_weights = {0:class_weights[0],1:class_weights[1],2:class_weights[2]}
class_weights

df['sentiment'].value_counts()

!pip install sentence-transformers
from sentence_transformers import SentenceTransformer
bert_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

embeddings = bert_model.encode(tweets, show_progress_bar=True)
print (embeddings.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(embeddings, labels1,
                                          test_size=0.1, random_state=42)
print ("Training set shapes:", X_train.shape, y_train.shape)
print ("Test set shapes:", X_test.shape, y_test.shape)

from tensorflow.keras import Sequential, layers
from tensorflow.keras.layers import Dense,Dropout
model = Sequential([
    Dense(256,activation = 'relu',input_dim = 768),
    Dropout(0.1),
    Dense(128,activation = 'relu'),
    Dropout(0.1),
    Dense(64,activation = 'relu'),
    Dense(32,activation= 'relu'),
    Dense(16,activation = 'relu'),
    Dropout(0.1),
    Dense(8,activation = 'relu'),
    Dense(3,activation = 'softmax')
])
model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])

model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs = 25,class_weight = class_weights)

model.save('model.h5')

